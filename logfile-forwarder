#!/usr/bin/env python
"""
Tails logfiles and forwards lines to various output sinks.
Right now stdout and Redis (same as logastash) are the available output sinks.

Config file is JSON format, similar options as logstash itself.  Sample:

{
    "input": [
        {
            "type":         "syslog",
            "path":         "/var/log/messages"
        }
    ],

    "output": [
        {
            "type":     "redis",
            "host":     "localhost",
            "key":      "syslogs"
        }
    ]
}

Input options:
    path:       path to logfile (required)
    type:       logstash 'type' field, for sorting logfile types. (required)
    add_field:  optional hash of fields + arguments to add to the message
    multiline:  optional regex pattern (escaped for JSON) that when matched indicates
                the current line belongs to the previous event

Output options:
    type:       'redis' or 'stdout'
    host:       Redis host (required for redis)
    port:       Redis port (optional)
    key:        Name of the redis list used for this log (required for redis)

Packages required: redis, pyinotify.

"""

__author__    = 'Michael Stella <michael@jwplayer.com>'
__copyright__ = "Copyright (c) 2013-2014 Long Tail Ad Solutions"
__version__   = "1.0"

import argparse
import logging
import os
import pyinotify
import re
import socket
import sys

import logstash

logging.basicConfig(level=logging.WARN, format='%(asctime)s %(levelname)-8s %(name)-6s %(message)s')
log_input=logging.getLogger('input')
log_output=logging.getLogger('output')

inputs = {}
outputs = []
hostname = None
notifier = None

class FileProcessor(pyinotify.ProcessEvent):
    """Processor class for inotify"""

    linebuffer = []

    def process_IN_CREATE(self, event):
        """Re-open the file when created"""

        path = os.path.join(event.path, event.name)
        if not path in inputs:
            return

        log_input.debug("Reopening file '{}'".format(path))

        i = inputs[path]
        f = open(i["path"], 'r')
        f.seek(0, 2)
        i['fh'] = f
        inputs[i['path']] = i


    def process_IN_DELETE(self, event):
        """Close the file handle when a file gets deleted, but don't
        stop watching it"""

        path = os.path.join(event.path, event.name)
        if path in inputs:
            log_input.debug("File '{}' deleted".format(path))
            inputs[path]['fh'].close()


    def process_IN_MODIFY(self, event):
        """When the file has changed, read the next line and log it"""
        path = os.path.join(event.path, event.name)

        if not path in inputs:
            return

        i = inputs[path]

        # file handle might not be open
        if not i['fh']:
            i['fh'] = open(i["path"], 'r')

        fh = i['fh']

        # figure out if we're seek'd past the end of the file,
        # and if so, seek back to the begining
        size = os.stat(path).st_size
        if fh.tell() > size:
            log_input.debug("File {} truncated".format(path))
            fh.seek(0,0)
            return


        # read a line, and build the output message
        for line in i['fh'].readlines():
            line = line.rstrip()

            # skip blanks
            if not line:
                continue

            # see if this is a multiline match
            if 'multiline' in i and re.match(i['multiline'], line, re.I):
                self.linebuffer.append(line)
                continue

            if self.linebuffer:
                # join up the multiline buffer
                self.linebuffer.append(line)
                line = '\n'.join(self.linebuffer)
                self.linebuffer = []

            data = {
                'message':  line,
                'type':     i['type'],
                'path':     path,
                'host':     hostname,
            }

            # add fields from the config file
            if 'add_field' in i:
                for k,v in i['add_field'].items():
                    if not k in data:
                        data[k] = v

            # send the message to all outputs
            for o in outputs:
                o.log(**data)


def init(args):
    global notifier

    logging.info("Startup")

    (cfginputs, cfgoutputs) = logstash.read_config(args.cfgfile[0])

    # connect to outputs
    for o in cfgoutputs:
        if o['type'] == 'redis':
            try:
                r = logstash.RedisSink(o['host'], o['key'])
                outputs.append(r)
                log_output.debug("Connected to redis server '{0}'".format(o['host']))

            except Exception as e:
                log_output.error("Redis: {0}".format(e))

        elif o['type'] == 'stdout':
            outputs.append(logstash.StdoutSink())


    wm = pyinotify.WatchManager()
    notifier = pyinotify.Notifier(wm, FileProcessor())

    # open input files
    for i in cfginputs:
        try:
            log_input.debug("Opening file '{0}'".format(i['path']))
            f = open(i["path"], 'r')
            f.seek(0, 2)
            i['fh'] = f
            inputs[i['path']] = i

            log_input.debug("Watching file '{0}'".format(i['path']))
            wm.add_watch(os.path.dirname(i['path']),
                pyinotify.IN_MODIFY|pyinotify.IN_DELETE|pyinotify.IN_CREATE
                )

        except IOError as e:
            log_input.error(e)


    if len(inputs) < 1:
        logging.error("No inputs, exiting")
        sys.exit(-1)

    if len(outputs) < 1:
        logging.error("No outputs, exiting")
        sys.exit(-1)


def run():
    """Run the loop"""

    ## loop
    while True:
        try:
            notifier.process_events()
            if notifier.check_events():
                notifier.read_events()
        except KeyboardInterrupt:
            break

    logging.info("Shutdown.")

    # cleanup: stop the inotify, and close the file handles:
    notifier.stop()
    for i in inputs.values():
        if i['fh']:
            i['fh'].close()


if __name__ == '__main__':
    argparser = argparse.ArgumentParser()
    argparser.add_argument('--debug', action='store_true', default=False)
    argparser.add_argument('cfgfile', nargs=1, help="JSON-format config file")

    opts = argparser.parse_args(sys.argv[1:])

    if opts.debug:
        log_input.setLevel(logging.DEBUG)
        log_output.setLevel(logging.DEBUG)

    hostname = socket.gethostname()
    init(opts)
    run()

